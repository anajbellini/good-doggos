{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Environment](#Environment)\n",
    "- [Gathering](#Gathering)\n",
    "    - [Twitter Archive](#Twitter-Archive)\n",
    "    - [Additional Data from Twitter API](#Additional-Data-from-Twitter-API)\n",
    "    - [Image Predictions](#Image-Predictions)\n",
    "- [Assessing](#Assessing)\n",
    "- [Cleaning](#Cleaning)\n",
    "    - [Tidiness issues](#Tidiness-issues)\n",
    "        - [Combining `archive_df` and `api_df`](#Combining-archive_df-and-api_df)\n",
    "        - [Combining `master_df_clean` and `images_df`](#Combining-master_df_clean-and-images_df)\n",
    "        - [Dog stage info should be in a single column](#Dog-stage-info-should-be-in-a-single-column)\n",
    "    - [Quality issues](#Quality-issues)\n",
    "        - [Keeping just one dog breed](#Keeping-just-one-dog-breed)\n",
    "        - [Removing Retweets](#Removing-Retweets)\n",
    "        - [Removing tweets with more than one dog stage](#Removing-tweets-with-more-than-one-dog-stage)\n",
    "        - [Fixing ratings](#Fixing-ratings)\n",
    "        - [Fixing `timestamp` and `retweeted_status_timestamp` datatype](#Fixing-timestamp-and-retweeted_status_timestamp-datatype)\n",
    "        - [Removing tweets from after Aug 1st, 2017](#Removing-tweets-from-after-Aug-1st,-2017)\n",
    "        - [Uppercase words and underscores in dog breed names](#Uppercase-words-and-underscores-in-dog-breed-names)\n",
    "        - [Invalid dog names](#Invalid-dog-names)\n",
    "        - [Removing unused columns](#Removing-unused-columns)\n",
    "        - [Null values](#Null-values)\n",
    "- [Storing](#Storing)\n",
    "- [Analysis](#Analysis)\n",
    "    - [Dog breeds](#Dog-breeds)\n",
    "        - [Most mentioned overall](#Most-mentioned-overall)\n",
    "        - [Most liked](#Most-liked)\n",
    "        - [Most retweeted](#Most-retweeted)\n",
    "    - [Names](#Names)\n",
    "        - [Most common](#Most-common)\n",
    "        - [Most common per breed](#Most-common-per-breed)\n",
    "    - [Stages](#Stages)\n",
    "        - [Tweets per stage](#Tweets-per-stage)\n",
    "        - [Likes per stage](#Likes-per-stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_context('notebook', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Archive\n",
    "\n",
    "This first part of our dataset comes directly from Udacity assignment. We just need to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df = pd.read_csv('./data/twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data from Twitter API\n",
    "\n",
    "Credentials come from my personal Twitter account, written in a separate JSON file for safety reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./params/\", \"twitter-api-credentials.json\"), \"r\") as config_file:\n",
    "    configs = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(configs['consumer_key'], configs['consumer_secret'])\n",
    "auth.set_access_token(configs['access_token'], configs['access_token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each tweet ID found within Udacity's archive, we call Twitter API to gather favorite and retweet counts. If we don't find the tweet for whatever reason, we save its ID within a dictionary, so we have it somewhere safe, in case we need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 232\n",
      "Rate limit reached. Sleeping for: 561\n"
     ]
    }
   ],
   "source": [
    "failed_api_queries = {}\n",
    "\n",
    "with open(os.path.join(\"./data/\", \"tweet_json.txt\"), \"w\") as tweet_file:\n",
    "    for tweet_id in archive_df.tweet_id.values:\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, tweet_file)\n",
    "            tweet_file.write(\"\\n\")\n",
    "        except Exception as exc:\n",
    "            failed_api_queries[tweet_id] = exc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the extra data gathered from the API, now we just read them into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./data/\", \"tweet_json.txt\"), \"r\") as file:\n",
    "    file_content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df_rows = []\n",
    "\n",
    "for line in file_content:\n",
    "    json_content = json.loads(line)\n",
    "    api_df_rows.append([json_content.get('id'), json_content.get('retweet_count'), json_content.get('favorite_count')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = pd.DataFrame.from_records(data=api_df_rows, columns=['tweet_id', 'retweet_count', 'favorite_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Predictions\n",
    "\n",
    "Another dataset from Udacity assignment, but we need to get this one with a HTTP request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "images_response = requests.get(images_url)\n",
    "images_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response comes in byte format, so we decode it and use `StringIO` to make it easier to work with response content as we would with a simple file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(io.StringIO(images_response.content.decode('utf-8')), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Archive\n",
    "\n",
    "### Quality\n",
    "- Null values in `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`, `expanded_urls`.\n",
    "- Some of the tweets are actually retweets and should be deleted, as per Udacity's request.\n",
    "- Wrong datatype in `timestamp` and `retweeted_status_timestamp`.\n",
    "- Invalid dog names (like \"a\", \"the\").\n",
    "- Invalid rating numerators.\n",
    "- Invalid rating denominators (they should always be 10).\n",
    "- Some tweets may mention two dogs (how would we know which one we extract data on?).\n",
    "- We need to remove tweets older than August 1st, 2017, as per another Udacity's request.\n",
    "- Some columns won't be used.\n",
    "\n",
    "### Tidiness\n",
    "- Dog stages should be contained in one column, not spread across four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(archive_df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the dog names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet_text in archive_df.query(\"name == 'the'\")['text']:\n",
    "    print(tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard rating system today (and a while ago) involves some score out of 10. Numerator can be greater than the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df['rating_numerator'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df['rating_denominator'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if there are tweets that mention more than one stage. If there are, we should just pick one, or none at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stages = ['doggo', 'pupper', 'puppo', 'floofer']\n",
    "dog_stages_found = {}\n",
    "\n",
    "for tweet in archive_df.tweet_id:\n",
    "    tweet_text = archive_df.query(\"tweet_id == @tweet\")['text'].values[0]\n",
    "    dog_stages_found[tweet] = sum(stage_count > 0 for stage_count in [tweet_text.count(stage) for stage in dog_stages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_1_stage = [key for key, value in dog_stages_found.items() if value > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in archive_df.query(\"tweet_id in @more_than_1_stage\")['text']:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking up on ratings with a denominator other than 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in archive_df.query(\"rating_denominator != 10\")['text']:\n",
    "    print(tweet, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checking the timespan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(archive_df['timestamp']), max(archive_df['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data from Twitter API\n",
    "\n",
    "### Quality\n",
    "- Some of the tweets were deleted since the dataset's creation, so they weren't found by the API.\n",
    "\n",
    "### Tidiness\n",
    "- This data should be part of the previous DataFrame, not a standalone dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(api_df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Predictions\n",
    "\n",
    "### Quality\n",
    "- Some breed names starting with uppercase.\n",
    "- Breed names with words separated by underscores, instead of whitespaces.\n",
    "- Non-descriptive column names.\n",
    "\n",
    "### Tidiness\n",
    "- These data should also be part of a main DataFrame.\n",
    "- Since we want just the dog breed, most of the columns won't be used here.\n",
    "- Dog breed could be in one of three different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(images_df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df['tweet_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(images_df.query('p1_dog')['p1'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean = archive_df.copy()\n",
    "api_df_clean = api_df.copy()\n",
    "images_df_clean = images_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining `archive_df` and `api_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "\n",
    "We'll combine `archive_df` and `api_df` into a single DataFrame, joining them by `tweet_id` column.\n",
    "\n",
    "By joining these datasets using \"inner join\", we get just the tweets contained in both of them, automatically solving the missing tweet data issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean = archive_df_clean.join(api_df_clean.set_index('tweet_id'), on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining `master_df_clean` and `images_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "\n",
    "We'll join both DataFrames just as we've done above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean = master_df_clean.join(images_df_clean.set_index('tweet_id'), on='tweet_id', how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog stage info should be in a single column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "\n",
    "We need to use a regular expression to extract the correct stage and create a new, unified column for the stages.\n",
    "\n",
    "For now, if there's more than one stage in a column, only the first one will be considered. We're taking a closer look on these cases later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['stage'] = master_df_clean['text'].str.extract(r'(doggo|pupper|puppo|floofer)')\n",
    "master_df_clean.drop(columns=['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['stage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping just one dog breed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Get the first confirmed dog breed along the three predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fact the columns `pred_1_is_a_dog`, `pred_2_is_a_dog` and `pred_3_is_a_dog` are Boolean, and Boolean variables can be added, we calculate the sum of \"dog predictions\" per tweet, and then find the first position where this count changes from 0 to 1 (meaning it's the first prediction that gave us a breed).\n",
    "\n",
    "We get first one, because there's an ordinal relationship between these predictions (i.e. the first prediction is always the one with the highest confidence score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_confirmations = master_df_clean[['p1_dog', 'p2_dog', 'p3_dog']]\n",
    "first_confirmation = (breed_confirmations.cumsum(axis=1) == 1).idxmax(axis=1)\n",
    "first_confirmation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the column index where the first identified breed is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_confirmed_breed = [master_df_clean.columns.get_loc(item) - 2 for item in first_confirmation] # considering we have pred_1, then pred_1_confidence, then pred_1 is a dog\n",
    "first_confirmed_breed[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finish the feature engineering process by creating a new column with the breed name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['breed'] = pd.Series([master_df_clean.iat[tweet, breed] for tweet, breed in zip(master_df_clean.index, first_confirmed_breed)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we delete the prediction columns, since we already have the information we ultimately wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.drop(columns=[\n",
    "    'p1', \n",
    "    'p1_conf', \n",
    "    'p1_dog', \n",
    "    'p2', \n",
    "    'p2_conf', \n",
    "    'p2_dog',\n",
    "    'p3', \n",
    "    'p3_conf', \n",
    "    'p3_dog'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['breed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Drop rows whose `retweeted_status_id` value is not null, as requested by Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean = master_df_clean[pd.isnull(master_df_clean['retweeted_status_id'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing tweets with more than one dog stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "First, we count how many dog stages (from a previously defined list) are there in the tweet content.\n",
    "\n",
    "After that, every tweet whose stage count is more than one will be dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stages = ['doggo', 'pupper', 'puppo', 'floofer']\n",
    "dog_stages_found = {}\n",
    "\n",
    "for tt_id in master_df_clean.tweet_id:\n",
    "    tweet_text = master_df_clean.query(\"tweet_id == @tt_id\")['text'].values[0]\n",
    "    dog_stages_found[tt_id] = sum(stage_count > 0 for stage_count in [tweet_text.count(stage) for stage in dog_stages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dog_stage_tweets = [key for key, value in dog_stages_found.items() if value > 1]\n",
    "len(invalid_dog_stage_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean = master_df_clean[~master_df_clean['tweet_id'].isin(invalid_dog_stage_tweets)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stages_test = {}\n",
    "\n",
    "for tweet in master_df_clean.tweet_id:\n",
    "    tweet_text = master_df_clean.query(\"tweet_id == @tweet\")['text'].values[0]\n",
    "    dog_stages_test[tweet] = sum(stage_count > 0 for stage_count in [tweet_text.count(stage) for stage in dog_stages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([key for key, value in dog_stages_test.items() if value > 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "\n",
    "Find tweets whose rating follows the \"XX/10\" pattern. Split this substring into two numerals, and then update `rating_numerator` and `rating_denominator`.\n",
    "\n",
    "If the tweet doesn't conform to this pattern, it'll be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt_id, tweet_text in zip(master_df_clean.tweet_id, master_df_clean.text):\n",
    "    rating_found = re.search(r'[0-9]+\\.*[0-9]*\\/10', tweet_text)\n",
    "    if rating_found is not None:\n",
    "        correct_num, correct_den = rating_found.group().split('/')\n",
    "        tweet_index = master_df_clean.index[master_df_clean['tweet_id'] == tt_id]\n",
    "        master_df_clean.at[tweet_index, 'rating_numerator'] = correct_num\n",
    "        master_df_clean.at[tweet_index, 'rating_denominator'] = correct_den\n",
    "    else:\n",
    "        master_df_clean = master_df_clean[master_df_clean['tweet_id'] != tt_id].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing `timestamp` and `retweeted_status_timestamp` datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Convert these columns from **object** to **datetime64**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['timestamp'] = pd.to_datetime(master_df_clean['timestamp'], format=\"%Y-%m-%d\")\n",
    "master_df_clean['retweeted_status_timestamp'] = pd.to_datetime(master_df_clean['retweeted_status_timestamp'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['timestamp'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['retweeted_status_timestamp'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing tweets from after Aug 1st, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Filter out rows whose `timestamp` is newer than this date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean = master_df_clean[master_df_clean['timestamp'].dt.date < datetime.date(2017, 8, 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(master_df_clean['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uppercase words and underscores in dog breed names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Convert columns `pred_1`, `pred_2` and `pred_3` into lowercase, and remove underscores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['breed'] = master_df_clean['breed'].str.replace(\"_\", \" \").str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(master_df_clean['breed'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid dog names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "\n",
    "Names start with capital letter. Let's keep only the rows whose `name` value follows this pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['name'] = master_df_clean['name'].apply(lambda n: \"Unknown\" if n.islower() else n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unused columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "\n",
    "We're focusing our analyses on likes, retweets, breeds, and so on. So we select other columns and drop them from our DataFrame to get cleaner, pristine, straight-to-the-point data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.drop(columns=[\n",
    "    'in_reply_to_status_id',\n",
    "    'in_reply_to_user_id',\n",
    "    'source',\n",
    "    'retweeted_status_id',\n",
    "    'retweeted_status_user_id',\n",
    "    'retweeted_status_timestamp',\n",
    "    'expanded_urls',\n",
    "    'jpg_url',\n",
    "    'img_num'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Strings will be filled with `np.nan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['stage'] = master_df_clean['stage'].fillna(np.nan)\n",
    "master_df_clean['name'] = master_df_clean['name'].replace('None', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.to_csv('./data/twitter_archive_master.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_data = master_df_clean.groupby('breed').agg({'tweet_id': 'count', 'favorite_count': sum, 'retweet_count': sum}).reset_index().rename(columns={'tweet_id': 'tweet_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most mentioned overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_breed_mentions = breed_data.sort_values(by='tweet_count', ascending=False).head(10)\n",
    "top_breed_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Doggo Stars: The 10 Most Mentioned Breeds Overall\")\n",
    "ax = sns.barplot(data=top_breed_mentions, x='tweet_count', y='breed', color='darkcyan')\n",
    "ax.set_xlabel(\"# of Tweets\")\n",
    "ax.set_ylabel(\"Breeds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_liked_breeds = breed_data.sort_values(by='favorite_count', ascending=False).head(10)\n",
    "most_liked_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Doggo Favorites: The 10 Most Liked Breeds\")\n",
    "ax = sns.barplot(data=most_liked_breeds, x='favorite_count', y='breed', color='darkorange')\n",
    "ax.set_xlabel(\"# of Likes\")\n",
    "ax.set_ylabel(\"Breeds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_retweeted_breeds = breed_data.sort_values(by='retweet_count', ascending=False).head(10)\n",
    "most_retweeted_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Our Doggo is Famous! The Most Retweeted Breeds\")\n",
    "ax = sns.barplot(data=most_retweeted_breeds, x='retweet_count', y='breed', color='darkcyan')\n",
    "ax.set_xlabel(\"# of Retweets\")\n",
    "ax.set_ylabel(\"Breeds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data = master_df_clean.query(\"name != 'Unknown'\")[['name', 'breed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = name_data.groupby('name').count().rename(columns={'breed': 'name_count'})\n",
    "top_names = top_names.reset_index().sort_values(by='name_count', ascending=False).head(10)\n",
    "top_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common per breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_breeds = top_breed_mentions['breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names_per_breed = name_data.query(\"breed in @top_breeds\").groupby('breed').agg(lambda x: x.value_counts().index[0])\n",
    "top_names_per_breed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_data = master_df_clean.query(\"stage != 'Unknown'\").groupby('stage').agg({'tweet_id': 'count', 'favorite_count': sum})\n",
    "stage_data = stage_data.reset_index().rename(columns={'tweet_id': 'tweet_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets per stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Stages of Doggo: Which Stages Showed Up the Most at @WeRateDogs?\")\n",
    "ax = sns.barplot(data=stage_data.sort_values(by='tweet_count', ascending=False), x='tweet_count', y='stage', color='darkcyan')\n",
    "ax.set_xlabel(\"# of Tweets\")\n",
    "ax.set_ylabel(\"Stages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likes per stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"How Do People Like the Doggo Stages?\")\n",
    "ax = sns.barplot(data=stage_data.sort_values(by='favorite_count', ascending=False), x='favorite_count', y='stage', color='darkorange')\n",
    "ax.set_xlabel(\"# of Likes\")\n",
    "ax.set_ylabel(\"Stages\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c62b783a36d4a54d04a71e7ccd8349d403cc9894e3f1b475fafe269c56e2d3b7"
  },
  "kernelspec": {
   "display_name": "Python [conda env:good-doggo]",
   "language": "python",
   "name": "conda-env-good-doggo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
